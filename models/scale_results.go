// Code generated by SQLBoiler 4.6.0 (https://github.com/volatiletech/sqlboiler). DO NOT EDIT.
// This file is meant to be re-generated in place and/or deleted at any time.

package models

import (
	"context"
	"database/sql"
	"fmt"
	"reflect"
	"strings"
	"sync"
	"time"

	"github.com/friendsofgo/errors"
	"github.com/volatiletech/null/v8"
	"github.com/volatiletech/sqlboiler/v4/boil"
	"github.com/volatiletech/sqlboiler/v4/queries"
	"github.com/volatiletech/sqlboiler/v4/queries/qm"
	"github.com/volatiletech/sqlboiler/v4/queries/qmhelper"
	"github.com/volatiletech/strmangle"
)

// ScaleResult is an object representing the database table.
type ScaleResult struct {
	ID                   null.Int64 `boil:"id" json:"id,omitempty" toml:"id" yaml:"id,omitempty"`
	Date                 string     `boil:"date" json:"date" toml:"date" yaml:"date"`
	Weight               float64    `boil:"weight" json:"weight" toml:"weight" yaml:"weight"`
	Bmi                  float64    `boil:"bmi" json:"bmi" toml:"bmi" yaml:"bmi"`
	BodyFatPercentage    float64    `boil:"body_fat_percentage" json:"body_fat_percentage" toml:"body_fat_percentage" yaml:"body_fat_percentage"`
	WaterPercentage      float64    `boil:"water_percentage" json:"water_percentage" toml:"water_percentage" yaml:"water_percentage"`
	MuscleMassPercentage float64    `boil:"muscle_mass_percentage" json:"muscle_mass_percentage" toml:"muscle_mass_percentage" yaml:"muscle_mass_percentage"`
	BoneMassPercentage   float64    `boil:"bone_mass_percentage" json:"bone_mass_percentage" toml:"bone_mass_percentage" yaml:"bone_mass_percentage"`
	BasalMetabolicRate   float64    `boil:"basal_metabolic_rate" json:"basal_metabolic_rate" toml:"basal_metabolic_rate" yaml:"basal_metabolic_rate"`
	VisceralFat          float64    `boil:"visceral_fat" json:"visceral_fat" toml:"visceral_fat" yaml:"visceral_fat"`
	LeanBodyMass         float64    `boil:"lean_body_mass" json:"lean_body_mass" toml:"lean_body_mass" yaml:"lean_body_mass"`
	BodyFatMass          float64    `boil:"body_fat_mass" json:"body_fat_mass" toml:"body_fat_mass" yaml:"body_fat_mass"`
	BoneMass             float64    `boil:"bone_mass" json:"bone_mass" toml:"bone_mass" yaml:"bone_mass"`
	MuscleMass           float64    `boil:"muscle_mass" json:"muscle_mass" toml:"muscle_mass" yaml:"muscle_mass"`
	BodyAge              float64    `boil:"body_age" json:"body_age" toml:"body_age" yaml:"body_age"`
	ProteinPercentage    float64    `boil:"protein_percentage" json:"protein_percentage" toml:"protein_percentage" yaml:"protein_percentage"`

	R *scaleResultR `boil:"-" json:"-" toml:"-" yaml:"-"`
	L scaleResultL  `boil:"-" json:"-" toml:"-" yaml:"-"`
}

var ScaleResultColumns = struct {
	ID                   string
	Date                 string
	Weight               string
	Bmi                  string
	BodyFatPercentage    string
	WaterPercentage      string
	MuscleMassPercentage string
	BoneMassPercentage   string
	BasalMetabolicRate   string
	VisceralFat          string
	LeanBodyMass         string
	BodyFatMass          string
	BoneMass             string
	MuscleMass           string
	BodyAge              string
	ProteinPercentage    string
}{
	ID:                   "id",
	Date:                 "date",
	Weight:               "weight",
	Bmi:                  "bmi",
	BodyFatPercentage:    "body_fat_percentage",
	WaterPercentage:      "water_percentage",
	MuscleMassPercentage: "muscle_mass_percentage",
	BoneMassPercentage:   "bone_mass_percentage",
	BasalMetabolicRate:   "basal_metabolic_rate",
	VisceralFat:          "visceral_fat",
	LeanBodyMass:         "lean_body_mass",
	BodyFatMass:          "body_fat_mass",
	BoneMass:             "bone_mass",
	MuscleMass:           "muscle_mass",
	BodyAge:              "body_age",
	ProteinPercentage:    "protein_percentage",
}

var ScaleResultTableColumns = struct {
	ID                   string
	Date                 string
	Weight               string
	Bmi                  string
	BodyFatPercentage    string
	WaterPercentage      string
	MuscleMassPercentage string
	BoneMassPercentage   string
	BasalMetabolicRate   string
	VisceralFat          string
	LeanBodyMass         string
	BodyFatMass          string
	BoneMass             string
	MuscleMass           string
	BodyAge              string
	ProteinPercentage    string
}{
	ID:                   "scale_results.id",
	Date:                 "scale_results.date",
	Weight:               "scale_results.weight",
	Bmi:                  "scale_results.bmi",
	BodyFatPercentage:    "scale_results.body_fat_percentage",
	WaterPercentage:      "scale_results.water_percentage",
	MuscleMassPercentage: "scale_results.muscle_mass_percentage",
	BoneMassPercentage:   "scale_results.bone_mass_percentage",
	BasalMetabolicRate:   "scale_results.basal_metabolic_rate",
	VisceralFat:          "scale_results.visceral_fat",
	LeanBodyMass:         "scale_results.lean_body_mass",
	BodyFatMass:          "scale_results.body_fat_mass",
	BoneMass:             "scale_results.bone_mass",
	MuscleMass:           "scale_results.muscle_mass",
	BodyAge:              "scale_results.body_age",
	ProteinPercentage:    "scale_results.protein_percentage",
}

// Generated where

type whereHelpernull_Int64 struct{ field string }

func (w whereHelpernull_Int64) EQ(x null.Int64) qm.QueryMod {
	return qmhelper.WhereNullEQ(w.field, false, x)
}
func (w whereHelpernull_Int64) NEQ(x null.Int64) qm.QueryMod {
	return qmhelper.WhereNullEQ(w.field, true, x)
}
func (w whereHelpernull_Int64) IsNull() qm.QueryMod    { return qmhelper.WhereIsNull(w.field) }
func (w whereHelpernull_Int64) IsNotNull() qm.QueryMod { return qmhelper.WhereIsNotNull(w.field) }
func (w whereHelpernull_Int64) LT(x null.Int64) qm.QueryMod {
	return qmhelper.Where(w.field, qmhelper.LT, x)
}
func (w whereHelpernull_Int64) LTE(x null.Int64) qm.QueryMod {
	return qmhelper.Where(w.field, qmhelper.LTE, x)
}
func (w whereHelpernull_Int64) GT(x null.Int64) qm.QueryMod {
	return qmhelper.Where(w.field, qmhelper.GT, x)
}
func (w whereHelpernull_Int64) GTE(x null.Int64) qm.QueryMod {
	return qmhelper.Where(w.field, qmhelper.GTE, x)
}

type whereHelperstring struct{ field string }

func (w whereHelperstring) EQ(x string) qm.QueryMod  { return qmhelper.Where(w.field, qmhelper.EQ, x) }
func (w whereHelperstring) NEQ(x string) qm.QueryMod { return qmhelper.Where(w.field, qmhelper.NEQ, x) }
func (w whereHelperstring) LT(x string) qm.QueryMod  { return qmhelper.Where(w.field, qmhelper.LT, x) }
func (w whereHelperstring) LTE(x string) qm.QueryMod { return qmhelper.Where(w.field, qmhelper.LTE, x) }
func (w whereHelperstring) GT(x string) qm.QueryMod  { return qmhelper.Where(w.field, qmhelper.GT, x) }
func (w whereHelperstring) GTE(x string) qm.QueryMod { return qmhelper.Where(w.field, qmhelper.GTE, x) }
func (w whereHelperstring) IN(slice []string) qm.QueryMod {
	values := make([]interface{}, 0, len(slice))
	for _, value := range slice {
		values = append(values, value)
	}
	return qm.WhereIn(fmt.Sprintf("%s IN ?", w.field), values...)
}
func (w whereHelperstring) NIN(slice []string) qm.QueryMod {
	values := make([]interface{}, 0, len(slice))
	for _, value := range slice {
		values = append(values, value)
	}
	return qm.WhereNotIn(fmt.Sprintf("%s NOT IN ?", w.field), values...)
}

type whereHelperfloat64 struct{ field string }

func (w whereHelperfloat64) EQ(x float64) qm.QueryMod { return qmhelper.Where(w.field, qmhelper.EQ, x) }
func (w whereHelperfloat64) NEQ(x float64) qm.QueryMod {
	return qmhelper.Where(w.field, qmhelper.NEQ, x)
}
func (w whereHelperfloat64) LT(x float64) qm.QueryMod { return qmhelper.Where(w.field, qmhelper.LT, x) }
func (w whereHelperfloat64) LTE(x float64) qm.QueryMod {
	return qmhelper.Where(w.field, qmhelper.LTE, x)
}
func (w whereHelperfloat64) GT(x float64) qm.QueryMod { return qmhelper.Where(w.field, qmhelper.GT, x) }
func (w whereHelperfloat64) GTE(x float64) qm.QueryMod {
	return qmhelper.Where(w.field, qmhelper.GTE, x)
}
func (w whereHelperfloat64) IN(slice []float64) qm.QueryMod {
	values := make([]interface{}, 0, len(slice))
	for _, value := range slice {
		values = append(values, value)
	}
	return qm.WhereIn(fmt.Sprintf("%s IN ?", w.field), values...)
}
func (w whereHelperfloat64) NIN(slice []float64) qm.QueryMod {
	values := make([]interface{}, 0, len(slice))
	for _, value := range slice {
		values = append(values, value)
	}
	return qm.WhereNotIn(fmt.Sprintf("%s NOT IN ?", w.field), values...)
}

var ScaleResultWhere = struct {
	ID                   whereHelpernull_Int64
	Date                 whereHelperstring
	Weight               whereHelperfloat64
	Bmi                  whereHelperfloat64
	BodyFatPercentage    whereHelperfloat64
	WaterPercentage      whereHelperfloat64
	MuscleMassPercentage whereHelperfloat64
	BoneMassPercentage   whereHelperfloat64
	BasalMetabolicRate   whereHelperfloat64
	VisceralFat          whereHelperfloat64
	LeanBodyMass         whereHelperfloat64
	BodyFatMass          whereHelperfloat64
	BoneMass             whereHelperfloat64
	MuscleMass           whereHelperfloat64
	BodyAge              whereHelperfloat64
	ProteinPercentage    whereHelperfloat64
}{
	ID:                   whereHelpernull_Int64{field: "\"scale_results\".\"id\""},
	Date:                 whereHelperstring{field: "\"scale_results\".\"date\""},
	Weight:               whereHelperfloat64{field: "\"scale_results\".\"weight\""},
	Bmi:                  whereHelperfloat64{field: "\"scale_results\".\"bmi\""},
	BodyFatPercentage:    whereHelperfloat64{field: "\"scale_results\".\"body_fat_percentage\""},
	WaterPercentage:      whereHelperfloat64{field: "\"scale_results\".\"water_percentage\""},
	MuscleMassPercentage: whereHelperfloat64{field: "\"scale_results\".\"muscle_mass_percentage\""},
	BoneMassPercentage:   whereHelperfloat64{field: "\"scale_results\".\"bone_mass_percentage\""},
	BasalMetabolicRate:   whereHelperfloat64{field: "\"scale_results\".\"basal_metabolic_rate\""},
	VisceralFat:          whereHelperfloat64{field: "\"scale_results\".\"visceral_fat\""},
	LeanBodyMass:         whereHelperfloat64{field: "\"scale_results\".\"lean_body_mass\""},
	BodyFatMass:          whereHelperfloat64{field: "\"scale_results\".\"body_fat_mass\""},
	BoneMass:             whereHelperfloat64{field: "\"scale_results\".\"bone_mass\""},
	MuscleMass:           whereHelperfloat64{field: "\"scale_results\".\"muscle_mass\""},
	BodyAge:              whereHelperfloat64{field: "\"scale_results\".\"body_age\""},
	ProteinPercentage:    whereHelperfloat64{field: "\"scale_results\".\"protein_percentage\""},
}

// ScaleResultRels is where relationship names are stored.
var ScaleResultRels = struct {
}{}

// scaleResultR is where relationships are stored.
type scaleResultR struct {
}

// NewStruct creates a new relationship struct
func (*scaleResultR) NewStruct() *scaleResultR {
	return &scaleResultR{}
}

// scaleResultL is where Load methods for each relationship are stored.
type scaleResultL struct{}

var (
	scaleResultAllColumns            = []string{"id", "date", "weight", "bmi", "body_fat_percentage", "water_percentage", "muscle_mass_percentage", "bone_mass_percentage", "basal_metabolic_rate", "visceral_fat", "lean_body_mass", "body_fat_mass", "bone_mass", "muscle_mass", "body_age", "protein_percentage"}
	scaleResultColumnsWithoutDefault = []string{}
	scaleResultColumnsWithDefault    = []string{"id", "date", "weight", "bmi", "body_fat_percentage", "water_percentage", "muscle_mass_percentage", "bone_mass_percentage", "basal_metabolic_rate", "visceral_fat", "lean_body_mass", "body_fat_mass", "bone_mass", "muscle_mass", "body_age", "protein_percentage"}
	scaleResultPrimaryKeyColumns     = []string{"id"}
)

type (
	// ScaleResultSlice is an alias for a slice of pointers to ScaleResult.
	// This should almost always be used instead of []ScaleResult.
	ScaleResultSlice []*ScaleResult
	// ScaleResultHook is the signature for custom ScaleResult hook methods
	ScaleResultHook func(context.Context, boil.ContextExecutor, *ScaleResult) error

	scaleResultQuery struct {
		*queries.Query
	}
)

// Cache for insert, update and upsert
var (
	scaleResultType                 = reflect.TypeOf(&ScaleResult{})
	scaleResultMapping              = queries.MakeStructMapping(scaleResultType)
	scaleResultPrimaryKeyMapping, _ = queries.BindMapping(scaleResultType, scaleResultMapping, scaleResultPrimaryKeyColumns)
	scaleResultInsertCacheMut       sync.RWMutex
	scaleResultInsertCache          = make(map[string]insertCache)
	scaleResultUpdateCacheMut       sync.RWMutex
	scaleResultUpdateCache          = make(map[string]updateCache)
	scaleResultUpsertCacheMut       sync.RWMutex
	scaleResultUpsertCache          = make(map[string]insertCache)
)

var (
	// Force time package dependency for automated UpdatedAt/CreatedAt.
	_ = time.Second
	// Force qmhelper dependency for where clause generation (which doesn't
	// always happen)
	_ = qmhelper.Where
)

var scaleResultBeforeInsertHooks []ScaleResultHook
var scaleResultBeforeUpdateHooks []ScaleResultHook
var scaleResultBeforeDeleteHooks []ScaleResultHook
var scaleResultBeforeUpsertHooks []ScaleResultHook

var scaleResultAfterInsertHooks []ScaleResultHook
var scaleResultAfterSelectHooks []ScaleResultHook
var scaleResultAfterUpdateHooks []ScaleResultHook
var scaleResultAfterDeleteHooks []ScaleResultHook
var scaleResultAfterUpsertHooks []ScaleResultHook

// doBeforeInsertHooks executes all "before insert" hooks.
func (o *ScaleResult) doBeforeInsertHooks(ctx context.Context, exec boil.ContextExecutor) (err error) {
	if boil.HooksAreSkipped(ctx) {
		return nil
	}

	for _, hook := range scaleResultBeforeInsertHooks {
		if err := hook(ctx, exec, o); err != nil {
			return err
		}
	}

	return nil
}

// doBeforeUpdateHooks executes all "before Update" hooks.
func (o *ScaleResult) doBeforeUpdateHooks(ctx context.Context, exec boil.ContextExecutor) (err error) {
	if boil.HooksAreSkipped(ctx) {
		return nil
	}

	for _, hook := range scaleResultBeforeUpdateHooks {
		if err := hook(ctx, exec, o); err != nil {
			return err
		}
	}

	return nil
}

// doBeforeDeleteHooks executes all "before Delete" hooks.
func (o *ScaleResult) doBeforeDeleteHooks(ctx context.Context, exec boil.ContextExecutor) (err error) {
	if boil.HooksAreSkipped(ctx) {
		return nil
	}

	for _, hook := range scaleResultBeforeDeleteHooks {
		if err := hook(ctx, exec, o); err != nil {
			return err
		}
	}

	return nil
}

// doBeforeUpsertHooks executes all "before Upsert" hooks.
func (o *ScaleResult) doBeforeUpsertHooks(ctx context.Context, exec boil.ContextExecutor) (err error) {
	if boil.HooksAreSkipped(ctx) {
		return nil
	}

	for _, hook := range scaleResultBeforeUpsertHooks {
		if err := hook(ctx, exec, o); err != nil {
			return err
		}
	}

	return nil
}

// doAfterInsertHooks executes all "after Insert" hooks.
func (o *ScaleResult) doAfterInsertHooks(ctx context.Context, exec boil.ContextExecutor) (err error) {
	if boil.HooksAreSkipped(ctx) {
		return nil
	}

	for _, hook := range scaleResultAfterInsertHooks {
		if err := hook(ctx, exec, o); err != nil {
			return err
		}
	}

	return nil
}

// doAfterSelectHooks executes all "after Select" hooks.
func (o *ScaleResult) doAfterSelectHooks(ctx context.Context, exec boil.ContextExecutor) (err error) {
	if boil.HooksAreSkipped(ctx) {
		return nil
	}

	for _, hook := range scaleResultAfterSelectHooks {
		if err := hook(ctx, exec, o); err != nil {
			return err
		}
	}

	return nil
}

// doAfterUpdateHooks executes all "after Update" hooks.
func (o *ScaleResult) doAfterUpdateHooks(ctx context.Context, exec boil.ContextExecutor) (err error) {
	if boil.HooksAreSkipped(ctx) {
		return nil
	}

	for _, hook := range scaleResultAfterUpdateHooks {
		if err := hook(ctx, exec, o); err != nil {
			return err
		}
	}

	return nil
}

// doAfterDeleteHooks executes all "after Delete" hooks.
func (o *ScaleResult) doAfterDeleteHooks(ctx context.Context, exec boil.ContextExecutor) (err error) {
	if boil.HooksAreSkipped(ctx) {
		return nil
	}

	for _, hook := range scaleResultAfterDeleteHooks {
		if err := hook(ctx, exec, o); err != nil {
			return err
		}
	}

	return nil
}

// doAfterUpsertHooks executes all "after Upsert" hooks.
func (o *ScaleResult) doAfterUpsertHooks(ctx context.Context, exec boil.ContextExecutor) (err error) {
	if boil.HooksAreSkipped(ctx) {
		return nil
	}

	for _, hook := range scaleResultAfterUpsertHooks {
		if err := hook(ctx, exec, o); err != nil {
			return err
		}
	}

	return nil
}

// AddScaleResultHook registers your hook function for all future operations.
func AddScaleResultHook(hookPoint boil.HookPoint, scaleResultHook ScaleResultHook) {
	switch hookPoint {
	case boil.BeforeInsertHook:
		scaleResultBeforeInsertHooks = append(scaleResultBeforeInsertHooks, scaleResultHook)
	case boil.BeforeUpdateHook:
		scaleResultBeforeUpdateHooks = append(scaleResultBeforeUpdateHooks, scaleResultHook)
	case boil.BeforeDeleteHook:
		scaleResultBeforeDeleteHooks = append(scaleResultBeforeDeleteHooks, scaleResultHook)
	case boil.BeforeUpsertHook:
		scaleResultBeforeUpsertHooks = append(scaleResultBeforeUpsertHooks, scaleResultHook)
	case boil.AfterInsertHook:
		scaleResultAfterInsertHooks = append(scaleResultAfterInsertHooks, scaleResultHook)
	case boil.AfterSelectHook:
		scaleResultAfterSelectHooks = append(scaleResultAfterSelectHooks, scaleResultHook)
	case boil.AfterUpdateHook:
		scaleResultAfterUpdateHooks = append(scaleResultAfterUpdateHooks, scaleResultHook)
	case boil.AfterDeleteHook:
		scaleResultAfterDeleteHooks = append(scaleResultAfterDeleteHooks, scaleResultHook)
	case boil.AfterUpsertHook:
		scaleResultAfterUpsertHooks = append(scaleResultAfterUpsertHooks, scaleResultHook)
	}
}

// One returns a single scaleResult record from the query.
func (q scaleResultQuery) One(ctx context.Context, exec boil.ContextExecutor) (*ScaleResult, error) {
	o := &ScaleResult{}

	queries.SetLimit(q.Query, 1)

	err := q.Bind(ctx, exec, o)
	if err != nil {
		if errors.Cause(err) == sql.ErrNoRows {
			return nil, sql.ErrNoRows
		}
		return nil, errors.Wrap(err, "models: failed to execute a one query for scale_results")
	}

	if err := o.doAfterSelectHooks(ctx, exec); err != nil {
		return o, err
	}

	return o, nil
}

// All returns all ScaleResult records from the query.
func (q scaleResultQuery) All(ctx context.Context, exec boil.ContextExecutor) (ScaleResultSlice, error) {
	var o []*ScaleResult

	err := q.Bind(ctx, exec, &o)
	if err != nil {
		return nil, errors.Wrap(err, "models: failed to assign all query results to ScaleResult slice")
	}

	if len(scaleResultAfterSelectHooks) != 0 {
		for _, obj := range o {
			if err := obj.doAfterSelectHooks(ctx, exec); err != nil {
				return o, err
			}
		}
	}

	return o, nil
}

// Count returns the count of all ScaleResult records in the query.
func (q scaleResultQuery) Count(ctx context.Context, exec boil.ContextExecutor) (int64, error) {
	var count int64

	queries.SetSelect(q.Query, nil)
	queries.SetCount(q.Query)

	err := q.Query.QueryRowContext(ctx, exec).Scan(&count)
	if err != nil {
		return 0, errors.Wrap(err, "models: failed to count scale_results rows")
	}

	return count, nil
}

// Exists checks if the row exists in the table.
func (q scaleResultQuery) Exists(ctx context.Context, exec boil.ContextExecutor) (bool, error) {
	var count int64

	queries.SetSelect(q.Query, nil)
	queries.SetCount(q.Query)
	queries.SetLimit(q.Query, 1)

	err := q.Query.QueryRowContext(ctx, exec).Scan(&count)
	if err != nil {
		return false, errors.Wrap(err, "models: failed to check if scale_results exists")
	}

	return count > 0, nil
}

// ScaleResults retrieves all the records using an executor.
func ScaleResults(mods ...qm.QueryMod) scaleResultQuery {
	mods = append(mods, qm.From("\"scale_results\""))
	return scaleResultQuery{NewQuery(mods...)}
}

// FindScaleResult retrieves a single record by ID with an executor.
// If selectCols is empty Find will return all columns.
func FindScaleResult(ctx context.Context, exec boil.ContextExecutor, iD null.Int64, selectCols ...string) (*ScaleResult, error) {
	scaleResultObj := &ScaleResult{}

	sel := "*"
	if len(selectCols) > 0 {
		sel = strings.Join(strmangle.IdentQuoteSlice(dialect.LQ, dialect.RQ, selectCols), ",")
	}
	query := fmt.Sprintf(
		"select %s from \"scale_results\" where \"id\"=?", sel,
	)

	q := queries.Raw(query, iD)

	err := q.Bind(ctx, exec, scaleResultObj)
	if err != nil {
		if errors.Cause(err) == sql.ErrNoRows {
			return nil, sql.ErrNoRows
		}
		return nil, errors.Wrap(err, "models: unable to select from scale_results")
	}

	if err = scaleResultObj.doAfterSelectHooks(ctx, exec); err != nil {
		return scaleResultObj, err
	}

	return scaleResultObj, nil
}

// Insert a single record using an executor.
// See boil.Columns.InsertColumnSet documentation to understand column list inference for inserts.
func (o *ScaleResult) Insert(ctx context.Context, exec boil.ContextExecutor, columns boil.Columns) error {
	if o == nil {
		return errors.New("models: no scale_results provided for insertion")
	}

	var err error

	if err := o.doBeforeInsertHooks(ctx, exec); err != nil {
		return err
	}

	nzDefaults := queries.NonZeroDefaultSet(scaleResultColumnsWithDefault, o)

	key := makeCacheKey(columns, nzDefaults)
	scaleResultInsertCacheMut.RLock()
	cache, cached := scaleResultInsertCache[key]
	scaleResultInsertCacheMut.RUnlock()

	if !cached {
		wl, returnColumns := columns.InsertColumnSet(
			scaleResultAllColumns,
			scaleResultColumnsWithDefault,
			scaleResultColumnsWithoutDefault,
			nzDefaults,
		)

		cache.valueMapping, err = queries.BindMapping(scaleResultType, scaleResultMapping, wl)
		if err != nil {
			return err
		}
		cache.retMapping, err = queries.BindMapping(scaleResultType, scaleResultMapping, returnColumns)
		if err != nil {
			return err
		}
		if len(wl) != 0 {
			cache.query = fmt.Sprintf("INSERT INTO \"scale_results\" (\"%s\") %%sVALUES (%s)%%s", strings.Join(wl, "\",\""), strmangle.Placeholders(dialect.UseIndexPlaceholders, len(wl), 1, 1))
		} else {
			cache.query = "INSERT INTO \"scale_results\" %sDEFAULT VALUES%s"
		}

		var queryOutput, queryReturning string

		if len(cache.retMapping) != 0 {
			cache.retQuery = fmt.Sprintf("SELECT \"%s\" FROM \"scale_results\" WHERE %s", strings.Join(returnColumns, "\",\""), strmangle.WhereClause("\"", "\"", 0, scaleResultPrimaryKeyColumns))
		}

		cache.query = fmt.Sprintf(cache.query, queryOutput, queryReturning)
	}

	value := reflect.Indirect(reflect.ValueOf(o))
	vals := queries.ValuesFromMapping(value, cache.valueMapping)

	if boil.IsDebug(ctx) {
		writer := boil.DebugWriterFrom(ctx)
		fmt.Fprintln(writer, cache.query)
		fmt.Fprintln(writer, vals)
	}
	_, err = exec.ExecContext(ctx, cache.query, vals...)

	if err != nil {
		return errors.Wrap(err, "models: unable to insert into scale_results")
	}

	var identifierCols []interface{}

	if len(cache.retMapping) == 0 {
		goto CacheNoHooks
	}

	identifierCols = []interface{}{
		o.ID,
	}

	if boil.IsDebug(ctx) {
		writer := boil.DebugWriterFrom(ctx)
		fmt.Fprintln(writer, cache.retQuery)
		fmt.Fprintln(writer, identifierCols...)
	}
	err = exec.QueryRowContext(ctx, cache.retQuery, identifierCols...).Scan(queries.PtrsFromMapping(value, cache.retMapping)...)
	if err != nil {
		return errors.Wrap(err, "models: unable to populate default values for scale_results")
	}

CacheNoHooks:
	if !cached {
		scaleResultInsertCacheMut.Lock()
		scaleResultInsertCache[key] = cache
		scaleResultInsertCacheMut.Unlock()
	}

	return o.doAfterInsertHooks(ctx, exec)
}

// Update uses an executor to update the ScaleResult.
// See boil.Columns.UpdateColumnSet documentation to understand column list inference for updates.
// Update does not automatically update the record in case of default values. Use .Reload() to refresh the records.
func (o *ScaleResult) Update(ctx context.Context, exec boil.ContextExecutor, columns boil.Columns) (int64, error) {
	var err error
	if err = o.doBeforeUpdateHooks(ctx, exec); err != nil {
		return 0, err
	}
	key := makeCacheKey(columns, nil)
	scaleResultUpdateCacheMut.RLock()
	cache, cached := scaleResultUpdateCache[key]
	scaleResultUpdateCacheMut.RUnlock()

	if !cached {
		wl := columns.UpdateColumnSet(
			scaleResultAllColumns,
			scaleResultPrimaryKeyColumns,
		)

		if !columns.IsWhitelist() {
			wl = strmangle.SetComplement(wl, []string{"created_at"})
		}
		if len(wl) == 0 {
			return 0, errors.New("models: unable to update scale_results, could not build whitelist")
		}

		cache.query = fmt.Sprintf("UPDATE \"scale_results\" SET %s WHERE %s",
			strmangle.SetParamNames("\"", "\"", 0, wl),
			strmangle.WhereClause("\"", "\"", 0, scaleResultPrimaryKeyColumns),
		)
		cache.valueMapping, err = queries.BindMapping(scaleResultType, scaleResultMapping, append(wl, scaleResultPrimaryKeyColumns...))
		if err != nil {
			return 0, err
		}
	}

	values := queries.ValuesFromMapping(reflect.Indirect(reflect.ValueOf(o)), cache.valueMapping)

	if boil.IsDebug(ctx) {
		writer := boil.DebugWriterFrom(ctx)
		fmt.Fprintln(writer, cache.query)
		fmt.Fprintln(writer, values)
	}
	var result sql.Result
	result, err = exec.ExecContext(ctx, cache.query, values...)
	if err != nil {
		return 0, errors.Wrap(err, "models: unable to update scale_results row")
	}

	rowsAff, err := result.RowsAffected()
	if err != nil {
		return 0, errors.Wrap(err, "models: failed to get rows affected by update for scale_results")
	}

	if !cached {
		scaleResultUpdateCacheMut.Lock()
		scaleResultUpdateCache[key] = cache
		scaleResultUpdateCacheMut.Unlock()
	}

	return rowsAff, o.doAfterUpdateHooks(ctx, exec)
}

// UpdateAll updates all rows with the specified column values.
func (q scaleResultQuery) UpdateAll(ctx context.Context, exec boil.ContextExecutor, cols M) (int64, error) {
	queries.SetUpdate(q.Query, cols)

	result, err := q.Query.ExecContext(ctx, exec)
	if err != nil {
		return 0, errors.Wrap(err, "models: unable to update all for scale_results")
	}

	rowsAff, err := result.RowsAffected()
	if err != nil {
		return 0, errors.Wrap(err, "models: unable to retrieve rows affected for scale_results")
	}

	return rowsAff, nil
}

// UpdateAll updates all rows with the specified column values, using an executor.
func (o ScaleResultSlice) UpdateAll(ctx context.Context, exec boil.ContextExecutor, cols M) (int64, error) {
	ln := int64(len(o))
	if ln == 0 {
		return 0, nil
	}

	if len(cols) == 0 {
		return 0, errors.New("models: update all requires at least one column argument")
	}

	colNames := make([]string, len(cols))
	args := make([]interface{}, len(cols))

	i := 0
	for name, value := range cols {
		colNames[i] = name
		args[i] = value
		i++
	}

	// Append all of the primary key values for each column
	for _, obj := range o {
		pkeyArgs := queries.ValuesFromMapping(reflect.Indirect(reflect.ValueOf(obj)), scaleResultPrimaryKeyMapping)
		args = append(args, pkeyArgs...)
	}

	sql := fmt.Sprintf("UPDATE \"scale_results\" SET %s WHERE %s",
		strmangle.SetParamNames("\"", "\"", 0, colNames),
		strmangle.WhereClauseRepeated(string(dialect.LQ), string(dialect.RQ), 0, scaleResultPrimaryKeyColumns, len(o)))

	if boil.IsDebug(ctx) {
		writer := boil.DebugWriterFrom(ctx)
		fmt.Fprintln(writer, sql)
		fmt.Fprintln(writer, args...)
	}
	result, err := exec.ExecContext(ctx, sql, args...)
	if err != nil {
		return 0, errors.Wrap(err, "models: unable to update all in scaleResult slice")
	}

	rowsAff, err := result.RowsAffected()
	if err != nil {
		return 0, errors.Wrap(err, "models: unable to retrieve rows affected all in update all scaleResult")
	}
	return rowsAff, nil
}

// Delete deletes a single ScaleResult record with an executor.
// Delete will match against the primary key column to find the record to delete.
func (o *ScaleResult) Delete(ctx context.Context, exec boil.ContextExecutor) (int64, error) {
	if o == nil {
		return 0, errors.New("models: no ScaleResult provided for delete")
	}

	if err := o.doBeforeDeleteHooks(ctx, exec); err != nil {
		return 0, err
	}

	args := queries.ValuesFromMapping(reflect.Indirect(reflect.ValueOf(o)), scaleResultPrimaryKeyMapping)
	sql := "DELETE FROM \"scale_results\" WHERE \"id\"=?"

	if boil.IsDebug(ctx) {
		writer := boil.DebugWriterFrom(ctx)
		fmt.Fprintln(writer, sql)
		fmt.Fprintln(writer, args...)
	}
	result, err := exec.ExecContext(ctx, sql, args...)
	if err != nil {
		return 0, errors.Wrap(err, "models: unable to delete from scale_results")
	}

	rowsAff, err := result.RowsAffected()
	if err != nil {
		return 0, errors.Wrap(err, "models: failed to get rows affected by delete for scale_results")
	}

	if err := o.doAfterDeleteHooks(ctx, exec); err != nil {
		return 0, err
	}

	return rowsAff, nil
}

// DeleteAll deletes all matching rows.
func (q scaleResultQuery) DeleteAll(ctx context.Context, exec boil.ContextExecutor) (int64, error) {
	if q.Query == nil {
		return 0, errors.New("models: no scaleResultQuery provided for delete all")
	}

	queries.SetDelete(q.Query)

	result, err := q.Query.ExecContext(ctx, exec)
	if err != nil {
		return 0, errors.Wrap(err, "models: unable to delete all from scale_results")
	}

	rowsAff, err := result.RowsAffected()
	if err != nil {
		return 0, errors.Wrap(err, "models: failed to get rows affected by deleteall for scale_results")
	}

	return rowsAff, nil
}

// DeleteAll deletes all rows in the slice, using an executor.
func (o ScaleResultSlice) DeleteAll(ctx context.Context, exec boil.ContextExecutor) (int64, error) {
	if len(o) == 0 {
		return 0, nil
	}

	if len(scaleResultBeforeDeleteHooks) != 0 {
		for _, obj := range o {
			if err := obj.doBeforeDeleteHooks(ctx, exec); err != nil {
				return 0, err
			}
		}
	}

	var args []interface{}
	for _, obj := range o {
		pkeyArgs := queries.ValuesFromMapping(reflect.Indirect(reflect.ValueOf(obj)), scaleResultPrimaryKeyMapping)
		args = append(args, pkeyArgs...)
	}

	sql := "DELETE FROM \"scale_results\" WHERE " +
		strmangle.WhereClauseRepeated(string(dialect.LQ), string(dialect.RQ), 0, scaleResultPrimaryKeyColumns, len(o))

	if boil.IsDebug(ctx) {
		writer := boil.DebugWriterFrom(ctx)
		fmt.Fprintln(writer, sql)
		fmt.Fprintln(writer, args)
	}
	result, err := exec.ExecContext(ctx, sql, args...)
	if err != nil {
		return 0, errors.Wrap(err, "models: unable to delete all from scaleResult slice")
	}

	rowsAff, err := result.RowsAffected()
	if err != nil {
		return 0, errors.Wrap(err, "models: failed to get rows affected by deleteall for scale_results")
	}

	if len(scaleResultAfterDeleteHooks) != 0 {
		for _, obj := range o {
			if err := obj.doAfterDeleteHooks(ctx, exec); err != nil {
				return 0, err
			}
		}
	}

	return rowsAff, nil
}

// Reload refetches the object from the database
// using the primary keys with an executor.
func (o *ScaleResult) Reload(ctx context.Context, exec boil.ContextExecutor) error {
	ret, err := FindScaleResult(ctx, exec, o.ID)
	if err != nil {
		return err
	}

	*o = *ret
	return nil
}

// ReloadAll refetches every row with matching primary key column values
// and overwrites the original object slice with the newly updated slice.
func (o *ScaleResultSlice) ReloadAll(ctx context.Context, exec boil.ContextExecutor) error {
	if o == nil || len(*o) == 0 {
		return nil
	}

	slice := ScaleResultSlice{}
	var args []interface{}
	for _, obj := range *o {
		pkeyArgs := queries.ValuesFromMapping(reflect.Indirect(reflect.ValueOf(obj)), scaleResultPrimaryKeyMapping)
		args = append(args, pkeyArgs...)
	}

	sql := "SELECT \"scale_results\".* FROM \"scale_results\" WHERE " +
		strmangle.WhereClauseRepeated(string(dialect.LQ), string(dialect.RQ), 0, scaleResultPrimaryKeyColumns, len(*o))

	q := queries.Raw(sql, args...)

	err := q.Bind(ctx, exec, &slice)
	if err != nil {
		return errors.Wrap(err, "models: unable to reload all in ScaleResultSlice")
	}

	*o = slice

	return nil
}

// ScaleResultExists checks if the ScaleResult row exists.
func ScaleResultExists(ctx context.Context, exec boil.ContextExecutor, iD null.Int64) (bool, error) {
	var exists bool
	sql := "select exists(select 1 from \"scale_results\" where \"id\"=? limit 1)"

	if boil.IsDebug(ctx) {
		writer := boil.DebugWriterFrom(ctx)
		fmt.Fprintln(writer, sql)
		fmt.Fprintln(writer, iD)
	}
	row := exec.QueryRowContext(ctx, sql, iD)

	err := row.Scan(&exists)
	if err != nil {
		return false, errors.Wrap(err, "models: unable to check if scale_results exists")
	}

	return exists, nil
}
